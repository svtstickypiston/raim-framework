{
    "id": 3,
    "feature_num": "03",
    "feature_name": "Controllability (conditioning)",
    "pillar_id": 1,
    "pillar": "Human Agency and Oversight",
    "facet": "Oversight",
    "feature_brief": "Users can control the AI's music generation using various inputs, like text, melodies, or rhythms.",
    "feature_summary": "Controllability lets users shape AI-generated music through text prompts, melodies, harmonies, or rhythms. By inputting text or uploading files, users can actively influence the creation process, increasing their involvement and control over the final output.",
    "feature_use_case": "This is about giving you the tools to shape the music the AI generates.  Instead of just saying \"make me a song,\" you can provide specific guidance.  You might type a text description (\"a sad piano piece in the style of Chopin\"), hum a melody, tap out a rhythm, or even select an emotion (\"happy,\" \"melancholy\") to guide the AI.  The more ways you can control the AI, the more it becomes a true extension of your creative vision.",
    "feature_long": "This feature is about giving you, the user, fine-grained control over the music the AI generates. Instead of just saying \"make a pop song,\" you can provide specific instructions or initial inputs to follow (alias conditioning). You might give it a starting melody, specify a particular chord progression, set the tempo, or even describe the desired mood (e.g., \"happy,\" \"melancholy,\" \"energetic\"). The system uses these conditions as a starting point, and may also allow control the generation via different modes of interaction, such as humming a tune, or drawing a rhythmic pattern. This multi-modal approach gives you the power to sculpt the music in detail, making the AI a collaborative tool."
}